{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4690b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Download required NLTK packages\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2fcbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\d+%', '', text)  # Remove percentages\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Replace punctuation with space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62ddd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity between two texts\n",
    "def calculate_cosine_similarity(text1, text2):\n",
    "    if pd.isna(text1) or pd.isna(text2) or text1 == \"\" or text2 == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "        return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# Function to calculate BLEU score between two texts\n",
    "def calculate_bleu_score(reference_text, candidate_text):\n",
    "    if pd.isna(reference_text) or pd.isna(candidate_text) or reference_text == \"\" or candidate_text == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    # Tokenize texts\n",
    "    reference_tokens = nltk.word_tokenize(reference_text.lower())\n",
    "    candidate_tokens = nltk.word_tokenize(candidate_text.lower())\n",
    "    \n",
    "    # Apply smoothing function for short texts\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    \n",
    "    try:\n",
    "        # Calculate BLEU score with different n-gram weights\n",
    "        bleu1 = sentence_bleu([reference_tokens], candidate_tokens, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "        bleu2 = sentence_bleu([reference_tokens], candidate_tokens, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
    "        bleu3 = sentence_bleu([reference_tokens], candidate_tokens, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothie)\n",
    "        bleu4 = sentence_bleu([reference_tokens], candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "        \n",
    "        # Average BLEU scores\n",
    "        avg_bleu = (bleu1 + bleu2 + bleu3 + bleu4) / 4\n",
    "        return avg_bleu\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# Function to calculate METEOR score between two texts\n",
    "def calculate_meteor_score(reference_text, candidate_text):\n",
    "    if pd.isna(reference_text) or pd.isna(candidate_text) or reference_text == \"\" or candidate_text == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    # Tokenize texts\n",
    "    reference_tokens = nltk.word_tokenize(reference_text.lower())\n",
    "    candidate_tokens = nltk.word_tokenize(candidate_text.lower())\n",
    "    \n",
    "    try:\n",
    "        return meteor_score([reference_tokens], candidate_tokens)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# Function to calculate BERT score\n",
    "def calculate_bert_score(reference_text, candidate_text):\n",
    "    if pd.isna(reference_text) or pd.isna(candidate_text) or reference_text == \"\" or candidate_text == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and encode texts\n",
    "    inputs1 = tokenizer(reference_text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs2 = tokenizer(candidate_text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Move inputs to the same device as model\n",
    "    inputs1 = {k: v.to(device) for k, v in inputs1.items()}\n",
    "    inputs2 = {k: v.to(device) for k, v in inputs2.items()}\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs1 = model(**inputs1)\n",
    "        outputs2 = model(**inputs2)\n",
    "    \n",
    "    # Use CLS token embeddings for sentence representation\n",
    "    embeddings1 = outputs1.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    embeddings2 = outputs2.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    # Calculate cosine similarity between embeddings\n",
    "    similarity = cosine_similarity(embeddings1, embeddings2)[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc3b25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved function to standardize disease names\n",
    "def standardize_disease_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    \n",
    "    name = str(name).lower().strip()\n",
    "    # Remove percentages\n",
    "    name = re.sub(r'\\d+%', '', name).strip()\n",
    "    \n",
    "    # Common variations of disease names to standardize - EXPANDED\n",
    "    mapping = {\n",
    "        # Demam (Fever) related\n",
    "        'dbd': 'demam berdarah dengue',\n",
    "        'dengue fever': 'demam berdarah dengue',\n",
    "        'demam dengue': 'demam berdarah dengue',\n",
    "        'dengue': 'demam berdarah dengue',\n",
    "        'demam berdarah': 'demam berdarah dengue',\n",
    "        'demam biasa': 'common fever',\n",
    "        'common fever': 'common fever',\n",
    "        'demam umum': 'common fever',\n",
    "        \n",
    "        # Gastro related\n",
    "        'gastroenteritis akut': 'gastroenteritis',\n",
    "        'gastroenteritis (ge) akut': 'gastroenteritis',\n",
    "        'ge akut': 'gastroenteritis',\n",
    "        'gastroenteritis': 'gastroenteritis',\n",
    "        'diare akut': 'gastroenteritis',\n",
    "        \n",
    "        # Respiratory related\n",
    "        'infeksi saluran pernapasan atas': 'ispa',\n",
    "        'ispa': 'ispa',\n",
    "        'infeksi saluran napas atas': 'ispa',\n",
    "        'infeksi saluran pernafasan atas': 'ispa',\n",
    "        'infeksi saluran pernapasan': 'ispa',\n",
    "        \n",
    "        # GERD related\n",
    "        'reflux gastroesofagus': 'gerd',\n",
    "        'reflux asam lambung': 'gerd',\n",
    "        'refleks asam lambung': 'gerd',\n",
    "        'gastroesophageal reflux disease': 'gerd',\n",
    "        'refleks gastroesofagus': 'gerd',\n",
    "        'gerd': 'gerd',\n",
    "        \n",
    "        # Gastritis related\n",
    "        'maag': 'gastritis',\n",
    "        'gastritis akut': 'gastritis',\n",
    "        'penyakit maag': 'gastritis',\n",
    "        'penyakit maag akut': 'gastritis',\n",
    "        'gastritis': 'gastritis',\n",
    "        \n",
    "        # Heart related\n",
    "        'infark miokard akut': 'serangan jantung',\n",
    "        'serangan jantung': 'serangan jantung',\n",
    "        'angina pektoris': 'angina',\n",
    "        'angina': 'angina',\n",
    "        \n",
    "        # Asthma related\n",
    "        'asma bronkial': 'asma',\n",
    "        'asma exacerbation': 'asma',\n",
    "        'asma': 'asma',\n",
    "        'pemburukan asma': 'asma',\n",
    "        \n",
    "        # Bronchitis related\n",
    "        'bronkitis akut': 'bronkitis',\n",
    "        'bronkitis': 'bronkitis',\n",
    "        \n",
    "        # Wound related\n",
    "        'vulnus laceratum': 'luka robek',\n",
    "        'luka robek': 'luka robek',\n",
    "        'luka terbuka': 'luka robek',\n",
    "        'laceration': 'luka robek',\n",
    "        'vulnus excoriatum': 'luka lecet',\n",
    "        'luka lecet': 'luka lecet',\n",
    "        \n",
    "        # Head injury related\n",
    "        'cedera kepala ringan': 'ckr',\n",
    "        'kepala cedera ringan': 'ckr',\n",
    "        'ckr': 'ckr',\n",
    "        \n",
    "        # Dyspepsia related\n",
    "        'dispepsia': 'dispepsia',\n",
    "        'dispepsia fungsional': 'dispepsia',\n",
    "        \n",
    "        # Appendicitis related\n",
    "        'appendisitis akut': 'appendisitis',\n",
    "        'appendisitis': 'appendisitis',\n",
    "        'apendisitis': 'appendisitis',\n",
    "        \n",
    "        # UTI related\n",
    "        'infeksi saluran kemih': 'isk',\n",
    "        'isk': 'isk',\n",
    "        'infeksi saluran kemih akut': 'isk',\n",
    "        \n",
    "        # Additional mappings\n",
    "        'intoleransi laktosa': 'intoleransi laktosa',\n",
    "        'pneumonia': 'pneumonia',\n",
    "        'hipertensi': 'hipertensi',\n",
    "        'hipertensi akut': 'hipertensi',\n",
    "        'hipertensi stage 1': 'hipertensi',\n",
    "        'luka bakar': 'luka bakar',\n",
    "        'burn injury': 'luka bakar',\n",
    "        'tonsilitis': 'tonsilitis',\n",
    "        'faringitis': 'faringitis',\n",
    "        'vertigo': 'vertigo',\n",
    "        'benign paroxysmal positional vertigo': 'vertigo',\n",
    "        'bppv': 'vertigo',\n",
    "        'influenza': 'influenza',\n",
    "        'kolik renal': 'kolik renal',\n",
    "        'batu ginjal': 'batu ginjal',\n",
    "        'peritonitis': 'peritonitis'\n",
    "    }\n",
    "    \n",
    "    # Apply mapping if available - using partial matching for more flexibility\n",
    "    for key, value in mapping.items():\n",
    "        if key in name:\n",
    "            return value\n",
    "    \n",
    "    # If no mapping found, return the cleaned name\n",
    "    return name\n",
    "\n",
    "# Function to extract percentage from diagnosis text\n",
    "def extract_percentage(text):\n",
    "    match = re.search(r'(\\d+)%', text)\n",
    "    return float(match.group(1))/100 if match else 0.5  # Default to 50% if not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cd8ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse diagnoses from raw answer text\n",
    "def parse_diagnoses(answer_text):\n",
    "    if pd.isna(answer_text):\n",
    "        return []\n",
    "    \n",
    "    # Split by semicolon and process each diagnosis\n",
    "    diagnoses = []\n",
    "    percentages = []\n",
    "    \n",
    "    for item in answer_text.split(';'):\n",
    "        item = item.strip()\n",
    "        if not item:\n",
    "            continue\n",
    "            \n",
    "        # Extract diagnosis name and percentage \n",
    "        match = re.search(r'(.*?)(?:\\s+(\\d+)%)?$', item)\n",
    "        if match and match.group(1).strip():\n",
    "            diagnoses.append(standardize_disease_name(match.group(1).strip()))\n",
    "            percentages.append(extract_percentage(item))\n",
    "    \n",
    "    # Create a list of tuples (diagnosis, percentage)\n",
    "    return list(zip(diagnoses, percentages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41068d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the best matching answer for a given Claude answer\n",
    "def select_best_answer(answers, claude_diagnoses):\n",
    "    \"\"\"\n",
    "    Selects the best matching Qwen answer based on overlap with Claude diagnoses\n",
    "    \n",
    "    Args:\n",
    "        answers: List of Qwen answer strings\n",
    "        claude_diagnoses: List of (diagnosis, score) tuples from Claude\n",
    "    \n",
    "    Returns:\n",
    "        best_answer: The Qwen answer with highest similarity score\n",
    "    \"\"\"\n",
    "    if not answers or not claude_diagnoses:\n",
    "        return \"\"\n",
    "    \n",
    "    best_score = -1\n",
    "    best_answer = \"\"\n",
    "    \n",
    "    claude_diseases = [d[0] for d in claude_diagnoses]\n",
    "    \n",
    "    for ans in answers:\n",
    "        parsed = parse_diagnoses(ans)\n",
    "        diseases = [d[0] for d in parsed]\n",
    "        print(ans, claude_diagnoses, claude_diseases, diseases)\n",
    "        \n",
    "        match_count = sum(1 for d in diseases if d in claude_diseases)\n",
    "        match_score = match_count / max(len(claude_diseases), len(diseases), 1)\n",
    "\n",
    "        print('match ', match_score)\n",
    "        \n",
    "        text_sim = calculate_cosine_similarity(\n",
    "            preprocess_text(ans), \n",
    "            preprocess_text('; '.join([d for d, _ in claude_diagnoses]))\n",
    "        )\n",
    "\n",
    "        print('sim ', text_sim)\n",
    "        \n",
    "        combined_score = (match_score * 0.7) + (text_sim * 0.3)\n",
    "        \n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_answer = ans\n",
    "            \n",
    "    return best_answer, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4daec43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate diagnosis matching metrics\n",
    "def calculate_diagnosis_match_metrics(claude_diagnoses, diagnose):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1 score for disease matching\n",
    "    \n",
    "    Args:\n",
    "        claude_diagnoses: List of (disease, score) tuples from Claude\n",
    "        diagnose: List of (disease, score) tuples from Qwen\n",
    "    \n",
    "    Returns:\n",
    "        dict with precision, recall, f1_score, etc.\n",
    "    \"\"\"\n",
    "    if not claude_diagnoses or not diagnose:\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1_score': 0.0,\n",
    "            'matched': 0,\n",
    "            'total_ground_truth': len(claude_diagnoses),\n",
    "            'total_predictions': len(diagnose)\n",
    "        }\n",
    "    \n",
    "    # Extract just the disease names\n",
    "    claude_diseases = [d[0] for d in claude_diagnoses]\n",
    "    diseases = [d[0] for d in diagnose]\n",
    "    \n",
    "    # Count matches\n",
    "    matches = sum(1 for d in diseases if d in claude_diseases)\n",
    "    \n",
    "    # Calculate precision: matches / qwen predictions\n",
    "    precision = matches / len(diseases) if diseases else 0\n",
    "    \n",
    "    # Calculate recall: matches / claude diagnoses (ground truth)\n",
    "    recall = matches / len(claude_diseases) if claude_diseases else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'matched': matches,\n",
    "        'total_ground_truth': len(claude_diseases),\n",
    "        'total_predictions': len(diseases)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5099cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_medical_diagnoses():\n",
    "    xlsx_path = 'evaulation/30 sample penyakit - hasil prompt LLM.xlsx'\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        claude_raw = pd.read_excel(xlsx_path, sheet_name='Claude 3.5 Haiku')\n",
    "        deepseek_raw = pd.read_excel(xlsx_path, sheet_name='Deepseek-V3-RAG')\n",
    "        \n",
    "        for df in [claude_raw, deepseek_raw]:\n",
    "            df['No'] = df['No'].ffill()\n",
    "            df['Question'] = df['Question'].ffill()\n",
    "        \n",
    "        claude_grouped = claude_raw.groupby(['No', 'Question'])\n",
    "        deepseek_grouped = deepseek_raw.groupby(['No', 'Question'])\n",
    "\n",
    "        print(deepseek_grouped)\n",
    "        \n",
    "        all_questions = list(set(claude_grouped.groups.keys()) | \n",
    "                             set(deepseek_grouped.groups.keys()) )\n",
    "        all_questions.sort(key=lambda x: float(x[0]) if x[0] is not None and not pd.isna(x[0]) else float('inf'))\n",
    "\n",
    "        all_results = []\n",
    "\n",
    "        # Evaluate for each model variant\n",
    "        for model_name, grouped_data in [('Deepseek', deepseek_grouped)]:\n",
    "            for idx, (no, question) in enumerate(all_questions):\n",
    "                try:\n",
    "                    print(f\"[{model_name}] Processing question {idx+1}/{len(all_questions)}: {no}\")\n",
    "\n",
    "                    if (no, question) not in claude_grouped.groups:\n",
    "                        print(f\"Warning: No Claude data for question {no}\")\n",
    "                        continue\n",
    "\n",
    "                    # Claude data\n",
    "                    claude_rows = claude_grouped.get_group((no, question))\n",
    "                    claude_answers = claude_rows['Answer'].dropna().tolist()\n",
    "                    claude_diagnoses = []\n",
    "                    for ans in claude_answers:\n",
    "                        claude_diagnoses.extend(parse_diagnoses(ans))\n",
    "                    claude_explanations = claude_rows['Full Answer'].dropna().tolist()\n",
    "                    claude_full_text = ' '.join(claude_explanations)\n",
    "\n",
    "                    # Model answer\n",
    "                    if (no, question) in grouped_data.groups:\n",
    "                        model_rows = grouped_data.get_group((no, question))\n",
    "                        model_answers = model_rows['Answer'].dropna().tolist()\n",
    "\n",
    "                        best_model_answer, similarity_score = select_best_answer(model_answers, claude_diagnoses)\n",
    "                        model_diagnoses = parse_diagnoses(best_model_answer)\n",
    "\n",
    "                        explanation_rows = model_rows[model_rows['Answer'] == best_model_answer]\n",
    "                        explanations = explanation_rows['Full Answer'].dropna().tolist()\n",
    "                        model_full_text = ' '.join(explanations) if explanations else \"\"\n",
    "                    else:\n",
    "                        print(f\"Warning: No {model_name} data for question {no}\")\n",
    "                        best_model_answer = \"\"\n",
    "                        similarity_score = 0.0\n",
    "                        model_diagnoses = []\n",
    "                        model_full_text = \"\"\n",
    "\n",
    "                    # Match metrics\n",
    "                    diagnosis_metrics = calculate_diagnosis_match_metrics(claude_diagnoses, model_diagnoses)\n",
    "                    claude_answer_text = '; '.join([f\"{d} {int(p*100)}%\" for d, p in claude_diagnoses])\n",
    "                    \n",
    "                    nlp_metrics = {\n",
    "                        'answer_cosine_similarity': calculate_cosine_similarity(\n",
    "                            preprocess_text(claude_answer_text), \n",
    "                            preprocess_text(best_model_answer)\n",
    "                        ),\n",
    "                        'full_answer_cosine_similarity': calculate_cosine_similarity(\n",
    "                            preprocess_text(claude_full_text), \n",
    "                            preprocess_text(model_full_text)\n",
    "                        ),\n",
    "                        'bleu_score': calculate_bleu_score(\n",
    "                            preprocess_text(claude_answer_text), \n",
    "                            preprocess_text(best_model_answer)\n",
    "                        ),\n",
    "                        'meteor_score': calculate_meteor_score(\n",
    "                            preprocess_text(claude_answer_text), \n",
    "                            preprocess_text(best_model_answer)\n",
    "                        ),\n",
    "                        'bert_score': calculate_bert_score(\n",
    "                            preprocess_text(claude_answer_text), \n",
    "                            preprocess_text(best_model_answer)\n",
    "                        )\n",
    "                    }\n",
    "\n",
    "                    # Append result\n",
    "                    result = {\n",
    "                        'Model': model_name,\n",
    "                        'No': no,\n",
    "                        'Question': question,\n",
    "                        'Claude_Diagnoses': claude_answer_text,\n",
    "                        'Selected_Model_Answer': best_model_answer,\n",
    "                        'Similarity_Score': similarity_score,\n",
    "                        **diagnosis_metrics,\n",
    "                        **nlp_metrics\n",
    "                    }\n",
    "\n",
    "                    all_results.append(result)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing question {no} for model {model_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        # Final DataFrame\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "\n",
    "        # Overall metrics per model\n",
    "        overall_metrics = results_df.groupby('Model').agg({\n",
    "            'precision': 'mean',\n",
    "            'recall': 'mean',\n",
    "            'f1_score': 'mean',\n",
    "            'answer_cosine_similarity': 'mean',\n",
    "            'full_answer_cosine_similarity': 'mean',\n",
    "            'bleu_score': 'mean',\n",
    "            'meteor_score': 'mean',\n",
    "            'bert_score': 'mean'\n",
    "        }).reset_index()\n",
    "        overall_metrics['total_questions'] = results_df.groupby('Model')['No'].nunique().values\n",
    "\n",
    "        return results_df, overall_metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Excel file: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e86ee91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting medical diagnosis evaluation...\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002B148327B10>\n",
      "[Deepseek] Processing question 1/50: 1.0\n",
      "Demam Tifoid (Typhoid Fever) [('demam tifoid', 0.7), ('demam berdarah dengue', 0.3)] ['demam tifoid', 'demam berdarah dengue'] ['demam tifoid (typhoid fever)']\n",
      "match  0.0\n",
      "sim  0.41106537098251733\n",
      "Malaria [('demam tifoid', 0.7), ('demam berdarah dengue', 0.3)] ['demam tifoid', 'demam berdarah dengue'] ['malaria']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Leptospirosis [('demam tifoid', 0.7), ('demam berdarah dengue', 0.3)] ['demam tifoid', 'demam berdarah dengue'] ['leptospirosis']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Infeksi Saluran Kemih (ISK) [('demam tifoid', 0.7), ('demam berdarah dengue', 0.3)] ['demam tifoid', 'demam berdarah dengue'] ['isk']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Sepsis [('demam tifoid', 0.7), ('demam berdarah dengue', 0.3)] ['demam tifoid', 'demam berdarah dengue'] ['sepsis']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "[Deepseek] Processing question 2/50: 2.0\n",
      "Gastroenteritis Akut [('gastroenteritis', 0.7), ('intoleransi laktosa', 0.3)] ['gastroenteritis', 'intoleransi laktosa'] ['gastroenteritis']\n",
      "match  0.5\n",
      "sim  0.2605556710562624\n",
      "Keracunan Makanan [('gastroenteritis', 0.7), ('intoleransi laktosa', 0.3)] ['gastroenteritis', 'intoleransi laktosa'] ['keracunan makanan']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Infeksi Bakteri (misalnya E. coli atau Shigella) [('gastroenteritis', 0.7), ('intoleransi laktosa', 0.3)] ['gastroenteritis', 'intoleransi laktosa'] ['infeksi bakteri (misalnya e. coli atau shigella)']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Dispepsia [('gastroenteritis', 0.7), ('intoleransi laktosa', 0.3)] ['gastroenteritis', 'intoleransi laktosa'] ['dispepsia']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Irritable Bowel Syndrome (IBS) [('gastroenteritis', 0.7), ('intoleransi laktosa', 0.3)] ['gastroenteritis', 'intoleransi laktosa'] ['irritable bowel syndrome (ibs)']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "[Deepseek] Processing question 3/50: 3.0\n",
      "Demam Berdarah Dengue (DBD) [('demam berdarah dengue', 0.8)] ['demam berdarah dengue'] ['demam berdarah dengue']\n",
      "match  1.0\n",
      "sim  0.7765145304745156\n",
      "Demam Tifoid [('demam berdarah dengue', 0.8)] ['demam berdarah dengue'] ['demam tifoid']\n",
      "match  0.0\n",
      "sim  0.2605556710562624\n",
      "Leptospirosis [('demam berdarah dengue', 0.8)] ['demam berdarah dengue'] ['leptospirosis']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Malaria [('demam berdarah dengue', 0.8)] ['demam berdarah dengue'] ['malaria']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Infeksi Virus Lain (misalnya, Chikungunya atau Zika) [('demam berdarah dengue', 0.8)] ['demam berdarah dengue'] ['infeksi virus lain (misalnya, chikungunya atau zika)']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "[Deepseek] Processing question 4/50: 4.0\n",
      "Warning: No Claude data for question 4.0\n",
      "[Deepseek] Processing question 5/50: 4.0\n",
      "Warning: No Deepseek data for question 4.0\n",
      "[Deepseek] Processing question 6/50: 5.0\n",
      "Angina Pectoris (Kardiovaskular) [('angina', 0.8), ('serangan jantung', 0.8)] ['angina', 'serangan jantung'] ['angina']\n",
      "match  0.5\n",
      "sim  0.20199309249791833\n",
      "Infark Miokard Akut (Kardiovaskular) [('angina', 0.8), ('serangan jantung', 0.8)] ['angina', 'serangan jantung'] ['serangan jantung']\n",
      "match  0.5\n",
      "sim  0.0\n",
      "Kolik Renal (Ginjal dan Saluran Kemih) [('angina', 0.8), ('serangan jantung', 0.8)] ['angina', 'serangan jantung'] ['kolik renal']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Penyakit Refluks Gastroesofageal (GERD) [('angina', 0.8), ('serangan jantung', 0.8)] ['angina', 'serangan jantung'] ['gerd']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Gangguan Muskuloskeletal [('angina', 0.8), ('serangan jantung', 0.8)] ['angina', 'serangan jantung'] ['gangguan muskuloskeletal']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "[Deepseek] Processing question 7/50: 6.0\n",
      "Warning: No Claude data for question 6.0\n",
      "[Deepseek] Processing question 8/50: 6.0\n",
      "Warning: No Deepseek data for question 6.0\n",
      "[Deepseek] Processing question 9/50: 7.0\n",
      "Warning: No Claude data for question 7.0\n",
      "[Deepseek] Processing question 10/50: 7.0\n",
      "Warning: No Deepseek data for question 7.0\n",
      "[Deepseek] Processing question 11/50: 8.0\n",
      "Asma [('bronkitis', 0.8), ('asma', 0.5)] ['bronkitis', 'asma'] ['asma']\n",
      "match  0.5\n",
      "sim  0.5797386715376658\n",
      "Pneumonia [('bronkitis', 0.8), ('asma', 0.5)] ['bronkitis', 'asma'] ['pneumonia']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Emboli Paru [('bronkitis', 0.8), ('asma', 0.5)] ['bronkitis', 'asma'] ['emboli paru']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Gagal Jantung Akut [('bronkitis', 0.8), ('asma', 0.5)] ['bronkitis', 'asma'] ['gagal jantung akut']\n",
      "match  0.0\n",
      "sim  0.0\n",
      "Penyakit Paru Obstruktif Kronis (PPOK) [('bronkitis', 0.8), ('asma', 0.5)] ['bronkitis', 'asma'] ['penyakit paru obstruktif kronis (ppok)']\n",
      "match  0.0\n",
      "sim  0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Function to run the full evaluation and display results\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting medical diagnosis evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m results_df, overall_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_medical_diagnoses\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     results_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeepseek_rag_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[31], line 82\u001b[0m, in \u001b[0;36mprocess_medical_diagnoses\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m diagnosis_metrics \u001b[38;5;241m=\u001b[39m calculate_diagnosis_match_metrics(claude_diagnoses, model_diagnoses)\n\u001b[0;32m     63\u001b[0m claude_answer_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(p\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d, p \u001b[38;5;129;01min\u001b[39;00m claude_diagnoses])\n\u001b[0;32m     65\u001b[0m nlp_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_cosine_similarity\u001b[39m\u001b[38;5;124m'\u001b[39m: calculate_cosine_similarity(\n\u001b[0;32m     67\u001b[0m         preprocess_text(claude_answer_text), \n\u001b[0;32m     68\u001b[0m         preprocess_text(best_model_answer)\n\u001b[0;32m     69\u001b[0m     ),\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_answer_cosine_similarity\u001b[39m\u001b[38;5;124m'\u001b[39m: calculate_cosine_similarity(\n\u001b[0;32m     71\u001b[0m         preprocess_text(claude_full_text), \n\u001b[0;32m     72\u001b[0m         preprocess_text(model_full_text)\n\u001b[0;32m     73\u001b[0m     ),\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbleu_score\u001b[39m\u001b[38;5;124m'\u001b[39m: calculate_bleu_score(\n\u001b[0;32m     75\u001b[0m         preprocess_text(claude_answer_text), \n\u001b[0;32m     76\u001b[0m         preprocess_text(best_model_answer)\n\u001b[0;32m     77\u001b[0m     ),\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeteor_score\u001b[39m\u001b[38;5;124m'\u001b[39m: calculate_meteor_score(\n\u001b[0;32m     79\u001b[0m         preprocess_text(claude_answer_text), \n\u001b[0;32m     80\u001b[0m         preprocess_text(best_model_answer)\n\u001b[0;32m     81\u001b[0m     ),\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcalculate_bert_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclaude_answer_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_answer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m }\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Append result\u001b[39;00m\n\u001b[0;32m     89\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_name,\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m: no,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnlp_metrics\n\u001b[0;32m     98\u001b[0m }\n",
      "Cell \u001b[1;32mIn[26], line 59\u001b[0m, in \u001b[0;36mcalculate_bert_score\u001b[1;34m(reference_text, candidate_text)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Load pre-trained BERT model and tokenizer\u001b[39;00m\n\u001b[0;32m     58\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Move model to GPU if available\u001b[39;00m\n\u001b[0;32m     62\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:262\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:4319\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   4312\u001b[0m     (\n\u001b[0;32m   4313\u001b[0m         model,\n\u001b[0;32m   4314\u001b[0m         missing_keys,\n\u001b[0;32m   4315\u001b[0m         unexpected_keys,\n\u001b[0;32m   4316\u001b[0m         mismatched_keys,\n\u001b[0;32m   4317\u001b[0m         offload_index,\n\u001b[0;32m   4318\u001b[0m         error_msgs,\n\u001b[1;32m-> 4319\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   4323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4326\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4330\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4331\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4339\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[0;32m   4340\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:4826\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[0;32m   4808\u001b[0m     error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m _load_state_dict_into_meta_model(\n\u001b[0;32m   4809\u001b[0m         model_to_load,\n\u001b[0;32m   4810\u001b[0m         fixed_state_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4822\u001b[0m         unexpected_keys\u001b[38;5;241m=\u001b[39munexpected_keys,\n\u001b[0;32m   4823\u001b[0m     )\n\u001b[0;32m   4824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4825\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n\u001b[1;32m-> 4826\u001b[0m     assign_to_params_buffers \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_support_param_buffer_assignment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\n\u001b[0;32m   4828\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4829\u001b[0m     fixed_state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fix_state_dict_keys_on_load(state_dict)\n\u001b[0;32m   4830\u001b[0m     error_msgs \u001b[38;5;241m=\u001b[39m _load_state_dict_into_model(\n\u001b[0;32m   4831\u001b[0m         model_to_load, fixed_state_dict, start_prefix, assign_to_params_buffers\n\u001b[0;32m   4832\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:421\u001b[0m, in \u001b[0;36mcheck_support_param_buffer_assignment\u001b[1;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# If the model does, the incoming `state_dict` and the `model_to_load` must be the same dtype\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m first_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mmodel_to_load\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_prefix \u001b[38;5;241m+\u001b[39m first_key \u001b[38;5;129;01min\u001b[39;00m state_dict:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state_dict[start_prefix \u001b[38;5;241m+\u001b[39m first_key]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m model_to_load\u001b[38;5;241m.\u001b[39mstate_dict()[first_key]\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2216\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2216\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   2222\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2216\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2216\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   2222\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "    \u001b[1;31m[... skipping similar frames: Module.state_dict at line 2216 (3 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2216\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2216\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   2222\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2213\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   2211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   2212\u001b[0m     hook(\u001b[38;5;28mself\u001b[39m, prefix, keep_vars)\n\u001b[1;32m-> 2213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_to_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2115\u001b[0m, in \u001b[0;36mModule._save_to_state_dict\u001b[1;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2115\u001b[0m         destination[prefix \u001b[38;5;241m+\u001b[39m name] \u001b[38;5;241m=\u001b[39m param \u001b[38;5;28;01mif\u001b[39;00m keep_vars \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, buf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_persistent_buffers_set:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to run the full evaluation and display results\n",
    "print(\"Starting medical diagnosis evaluation...\")\n",
    "results_df, overall_metrics = process_medical_diagnoses()\n",
    "\n",
    "if results_df is not None:\n",
    "    results_df.to_csv('deepseek_rag_results.csv', index=False)\n",
    "else:\n",
    "    print(\"Error: Evaluation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e02445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>matched</th>\n",
       "      <th>total_ground_truth</th>\n",
       "      <th>total_predictions</th>\n",
       "      <th>answer_cosine_similarity</th>\n",
       "      <th>full_answer_cosine_similarity</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>meteor_score</th>\n",
       "      <th>bert_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.691118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              No  Similarity_Score  precision  recall  f1_score  matched  \\\n",
       "count   5.000000               5.0        5.0     5.0       5.0      5.0   \n",
       "mean   12.400000               0.0        0.0     0.0       0.0      0.0   \n",
       "std    10.691118               0.0        0.0     0.0       0.0      0.0   \n",
       "min     4.000000               0.0        0.0     0.0       0.0      0.0   \n",
       "25%     6.000000               0.0        0.0     0.0       0.0      0.0   \n",
       "50%     7.000000               0.0        0.0     0.0       0.0      0.0   \n",
       "75%    15.000000               0.0        0.0     0.0       0.0      0.0   \n",
       "max    30.000000               0.0        0.0     0.0       0.0      0.0   \n",
       "\n",
       "       total_ground_truth  total_predictions  answer_cosine_similarity  \\\n",
       "count            5.000000                5.0                       5.0   \n",
       "mean             2.000000                0.0                       0.0   \n",
       "std              0.707107                0.0                       0.0   \n",
       "min              1.000000                0.0                       0.0   \n",
       "25%              2.000000                0.0                       0.0   \n",
       "50%              2.000000                0.0                       0.0   \n",
       "75%              2.000000                0.0                       0.0   \n",
       "max              3.000000                0.0                       0.0   \n",
       "\n",
       "       full_answer_cosine_similarity  bleu_score  meteor_score  bert_score  \n",
       "count                            5.0         5.0           5.0         5.0  \n",
       "mean                             0.0         0.0           0.0         0.0  \n",
       "std                              0.0         0.0           0.0         0.0  \n",
       "min                              0.0         0.0           0.0         0.0  \n",
       "25%                              0.0         0.0           0.0         0.0  \n",
       "50%                              0.0         0.0           0.0         0.0  \n",
       "75%                              0.0         0.0           0.0         0.0  \n",
       "max                              0.0         0.0           0.0         0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
