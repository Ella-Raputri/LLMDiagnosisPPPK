{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY2\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Question</th>\n",
              "      <th>Dr Answer</th>\n",
              "      <th>Claude Answer</th>\n",
              "      <th>Qwen Answer</th>\n",
              "      <th>GPT Answer</th>\n",
              "      <th>Deepseek RAG Answer</th>\n",
              "      <th>Deepseek non RAG Answer</th>\n",
              "      <th>Claude Full Answer</th>\n",
              "      <th>Qwen Full Answer</th>\n",
              "      <th>GPT Full Answer</th>\n",
              "      <th>Deepseek RAG Full Answer</th>\n",
              "      <th>Deepseek non RAG Full Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Pasien mengalami demam pada waktu malam. Sebel...</td>\n",
              "      <td>Demam Tifoid 70%, Demam Berdarah Dengue 30%</td>\n",
              "      <td>Demam Tifoid, Leptospirosis, Demam Berdarah De...</td>\n",
              "      <td>Demam Biasa, Dispepsia, Asma, Infeksi Saluran ...</td>\n",
              "      <td>Demam Biasa, Demam Tifoid, Demam Berdarah Deng...</td>\n",
              "      <td>Demam Tifoid (Typhoid Fever), Malaria, Leptosp...</td>\n",
              "      <td>Malaria, Infeksi Saluran Kemih (ISK) atau Piel...</td>\n",
              "      <td>Berdasarkan gejala yang disampaikan, saya akan...</td>\n",
              "      <td>Berdasarkan gejala yang disampaikan, yaitu dem...</td>\n",
              "      <td>Berdasarkan gejala yang disampaikan, yaitu dem...</td>\n",
              "      <td>Berdasarkan gejala yang dialami pasien, yaitu ...</td>\n",
              "      <td>Berdasarkan gejala yang Anda sebutkan—demam pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Pasien mengalami buang air besar cair lebih da...</td>\n",
              "      <td>Gastroenteritis (GE) Akut 70%, Intoleransi Lak...</td>\n",
              "      <td>Gastroenteritis (GE) Akut, Disentri, Infeksi E...</td>\n",
              "      <td>Diare Akut, Gastroenteritis, Dispepsia, Infeks...</td>\n",
              "      <td>Gastroenteritis Akut, Infeksi Escherichia coli...</td>\n",
              "      <td>Gastroenteritis Akut, Keracunan Makanan, Infek...</td>\n",
              "      <td>Gastroenteritis Akut, Keracunan Makanan, Koler...</td>\n",
              "      <td>Berdasarkan informasi klinis yang diberikan, s...</td>\n",
              "      <td>Berdasarkan gejala yang disampaikan, yaitu bua...</td>\n",
              "      <td>Berdasarkan informasi yang diberikan, pasien m...</td>\n",
              "      <td>Berdasarkan informasi yang diberikan, pasien m...</td>\n",
              "      <td>Berdasarkan gejala yang Anda deskripsikan—diar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Pasien datang dengan keluhan demam selama 6 ha...</td>\n",
              "      <td>DBD 80%</td>\n",
              "      <td>Demam Tifoid, Malaria, DBD, Leptospirosis, Inf...</td>\n",
              "      <td>Demam Biasa, Dispepsia, Asma, Demam Dengue, Lu...</td>\n",
              "      <td>Demam Berdarah Dengue, Demam Tifoid, Malaria, ...</td>\n",
              "      <td>Demam Berdarah Dengue (DBD), Demam Tifoid, Lep...</td>\n",
              "      <td>Demam Berdarah Dengue (DBD) / Dengue Fever, Ch...</td>\n",
              "      <td>Berdasarkan informasi yang diberikan, saya aka...</td>\n",
              "      <td>Berdasarkan gejala yang disampaikan, yaitu dem...</td>\n",
              "      <td>Berdasarkan keluhan yang disampaikan oleh pasi...</td>\n",
              "      <td>Berdasarkan keluhan pasien yang meliputi demam...</td>\n",
              "      <td>Berdasarkan gejala yang Anda sebutkan—demam ≥6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Pasien menderita demam disertai munculnya brun...</td>\n",
              "      <td>Infeksi Bakteri/Virus (Sistemik) 50%, Infeksi ...</td>\n",
              "      <td>DBD, Infeksi Bakteri/Virus (Sistemik), Infeksi...</td>\n",
              "      <td>Demam Biasa, Dispepsia, Asma, Infeksi Lokal, A...</td>\n",
              "      <td>Infeksi Kulit (Dermatitis atau Selulitis), Kej...</td>\n",
              "      <td>Infeksi Bakteri (Selulitis), Reaksi Alergi (De...</td>\n",
              "      <td>Erisipelas (Infeksi Bakteri pada Kulit dan Jar...</td>\n",
              "      <td>Berdasarkan informasi klinis yang diberikan, s...</td>\n",
              "      <td>Berdasarkan gejala yang disampaikan, yaitu dem...</td>\n",
              "      <td>Berdasarkan informasi yang diberikan, pasien m...</td>\n",
              "      <td>### Analisis Gejala dan Kemungkinan Diagnosis\\...</td>\n",
              "      <td>Berdasarkan gejala dan temuan pemeriksaan yang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Pasien nyeri dada sejak 4 jam lalu seperti ter...</td>\n",
              "      <td>Angina Pekrotis 80%, Infark Miokard Akut (Sera...</td>\n",
              "      <td>Angina Pekrotis, Infark Miokard Akut (Serangan...</td>\n",
              "      <td>Infark Miokard Akut (Serangan Jantung), Dispep...</td>\n",
              "      <td>Angina Pekrotis, Infark Miokard, Penyakit Musk...</td>\n",
              "      <td>Angina Pectoris (Kardiovaskular), Infark Mioka...</td>\n",
              "      <td>Infark Miokard Akut (Serangan Jantung), Angina...</td>\n",
              "      <td>Berdasarkan informasi yang diberikan dalam kon...</td>\n",
              "      <td>Berdasarkan gejala yang disampaikan, yaitu nye...</td>\n",
              "      <td>Berdasarkan informasi yang diberikan, pasien m...</td>\n",
              "      <td>### Analisis Gejala\\r\\n\\r\\nPasien mengeluhkan ...</td>\n",
              "      <td>Berdasarkan gejala nyeri dada seperti terhimpi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    No                                           Question  \\\n",
              "0  1.0  Pasien mengalami demam pada waktu malam. Sebel...   \n",
              "1  2.0  Pasien mengalami buang air besar cair lebih da...   \n",
              "2  3.0  Pasien datang dengan keluhan demam selama 6 ha...   \n",
              "3  4.0  Pasien menderita demam disertai munculnya brun...   \n",
              "4  5.0  Pasien nyeri dada sejak 4 jam lalu seperti ter...   \n",
              "\n",
              "                                           Dr Answer  \\\n",
              "0        Demam Tifoid 70%, Demam Berdarah Dengue 30%   \n",
              "1  Gastroenteritis (GE) Akut 70%, Intoleransi Lak...   \n",
              "2                                            DBD 80%   \n",
              "3  Infeksi Bakteri/Virus (Sistemik) 50%, Infeksi ...   \n",
              "4  Angina Pekrotis 80%, Infark Miokard Akut (Sera...   \n",
              "\n",
              "                                       Claude Answer  \\\n",
              "0  Demam Tifoid, Leptospirosis, Demam Berdarah De...   \n",
              "1  Gastroenteritis (GE) Akut, Disentri, Infeksi E...   \n",
              "2  Demam Tifoid, Malaria, DBD, Leptospirosis, Inf...   \n",
              "3  DBD, Infeksi Bakteri/Virus (Sistemik), Infeksi...   \n",
              "4  Angina Pekrotis, Infark Miokard Akut (Serangan...   \n",
              "\n",
              "                                         Qwen Answer  \\\n",
              "0  Demam Biasa, Dispepsia, Asma, Infeksi Saluran ...   \n",
              "1  Diare Akut, Gastroenteritis, Dispepsia, Infeks...   \n",
              "2  Demam Biasa, Dispepsia, Asma, Demam Dengue, Lu...   \n",
              "3  Demam Biasa, Dispepsia, Asma, Infeksi Lokal, A...   \n",
              "4  Infark Miokard Akut (Serangan Jantung), Dispep...   \n",
              "\n",
              "                                          GPT Answer  \\\n",
              "0  Demam Biasa, Demam Tifoid, Demam Berdarah Deng...   \n",
              "1  Gastroenteritis Akut, Infeksi Escherichia coli...   \n",
              "2  Demam Berdarah Dengue, Demam Tifoid, Malaria, ...   \n",
              "3  Infeksi Kulit (Dermatitis atau Selulitis), Kej...   \n",
              "4  Angina Pekrotis, Infark Miokard, Penyakit Musk...   \n",
              "\n",
              "                                 Deepseek RAG Answer  \\\n",
              "0  Demam Tifoid (Typhoid Fever), Malaria, Leptosp...   \n",
              "1  Gastroenteritis Akut, Keracunan Makanan, Infek...   \n",
              "2  Demam Berdarah Dengue (DBD), Demam Tifoid, Lep...   \n",
              "3  Infeksi Bakteri (Selulitis), Reaksi Alergi (De...   \n",
              "4  Angina Pectoris (Kardiovaskular), Infark Mioka...   \n",
              "\n",
              "                             Deepseek non RAG Answer  \\\n",
              "0  Malaria, Infeksi Saluran Kemih (ISK) atau Piel...   \n",
              "1  Gastroenteritis Akut, Keracunan Makanan, Koler...   \n",
              "2  Demam Berdarah Dengue (DBD) / Dengue Fever, Ch...   \n",
              "3  Erisipelas (Infeksi Bakteri pada Kulit dan Jar...   \n",
              "4  Infark Miokard Akut (Serangan Jantung), Angina...   \n",
              "\n",
              "                                  Claude Full Answer  \\\n",
              "0  Berdasarkan gejala yang disampaikan, saya akan...   \n",
              "1  Berdasarkan informasi klinis yang diberikan, s...   \n",
              "2  Berdasarkan informasi yang diberikan, saya aka...   \n",
              "3  Berdasarkan informasi klinis yang diberikan, s...   \n",
              "4  Berdasarkan informasi yang diberikan dalam kon...   \n",
              "\n",
              "                                    Qwen Full Answer  \\\n",
              "0  Berdasarkan gejala yang disampaikan, yaitu dem...   \n",
              "1  Berdasarkan gejala yang disampaikan, yaitu bua...   \n",
              "2  Berdasarkan gejala yang disampaikan, yaitu dem...   \n",
              "3  Berdasarkan gejala yang disampaikan, yaitu dem...   \n",
              "4  Berdasarkan gejala yang disampaikan, yaitu nye...   \n",
              "\n",
              "                                     GPT Full Answer  \\\n",
              "0  Berdasarkan gejala yang disampaikan, yaitu dem...   \n",
              "1  Berdasarkan informasi yang diberikan, pasien m...   \n",
              "2  Berdasarkan keluhan yang disampaikan oleh pasi...   \n",
              "3  Berdasarkan informasi yang diberikan, pasien m...   \n",
              "4  Berdasarkan informasi yang diberikan, pasien m...   \n",
              "\n",
              "                            Deepseek RAG Full Answer  \\\n",
              "0  Berdasarkan gejala yang dialami pasien, yaitu ...   \n",
              "1  Berdasarkan informasi yang diberikan, pasien m...   \n",
              "2  Berdasarkan keluhan pasien yang meliputi demam...   \n",
              "3  ### Analisis Gejala dan Kemungkinan Diagnosis\\...   \n",
              "4  ### Analisis Gejala\\r\\n\\r\\nPasien mengeluhkan ...   \n",
              "\n",
              "                        Deepseek non RAG Full Answer  \n",
              "0  Berdasarkan gejala yang Anda sebutkan—demam pa...  \n",
              "1  Berdasarkan gejala yang Anda deskripsikan—diar...  \n",
              "2  Berdasarkan gejala yang Anda sebutkan—demam ≥6...  \n",
              "3  Berdasarkan gejala dan temuan pemeriksaan yang...  \n",
              "4  Berdasarkan gejala nyeri dada seperti terhimpi...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../cleaning_before_eval/ready_to_eval.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('kamus.json', 'r') as file:\n",
        "    SYNONYM_MAP = json.load(file)\n",
        "    \n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    for abbr, canonical in SYNONYM_MAP.items():\n",
        "        abb = abbr.lower()\n",
        "        canon = canonical.lower()\n",
        "\n",
        "        if (text == canon): break\n",
        "        pattern = rf'\\b{re.escape(abb)}\\b'\n",
        "        if re.search(pattern, text):\n",
        "            text = re.sub(pattern, canon, text)\n",
        "            break\n",
        "        \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def llm_judge_answer(question, candidate_answer:str, gt_answers:str, model_name=\"gpt-3.5-turbo\", max_retries=3):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            if attempt > 0:\n",
        "                delay = 2 ** attempt  \n",
        "                print(f\"Retrying after {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "            \n",
        "            normalized_candidate = normalize_text(candidate_answer)\n",
        "            ground_truth_text = normalize_text(gt_answers)\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            You are a medical expert evaluating diagnosis answers. Please judge if the candidate answer is appropriate given the ground truth.\n",
        "\n",
        "            Question: {question}\n",
        "            Ground Truth Answers: {ground_truth_text}\n",
        "            Candidate Answer: {normalized_candidate}\n",
        "\n",
        "            Please evaluate if the candidate answer is:\n",
        "            1. Correct and matches the ground truth\n",
        "            2. Partially correct or related\n",
        "            3. Incorrect or unrelated\n",
        "\n",
        "            Provide your response as a JSON object with the following structure:\n",
        "            {{\n",
        "                \"score\": <score from 0 to 1, where 1 is perfect match between ground truth and candidate answer>,\n",
        "                \"reasoning\": \"<brief explanation of your judgment>\",\n",
        "                \"category\": \"<correct|partial|incorrect>\"\n",
        "            }}\n",
        "\n",
        "            Response:\"\"\"\n",
        "\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a medical expert evaluating diagnosis accuracy.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.1,\n",
        "                max_tokens=200\n",
        "            )\n",
        "\n",
        "            response_text = response.choices[0].message.content\n",
        "            # print(response_text)\n",
        "            try:\n",
        "                start_idx = response_text.find('{')\n",
        "                end_idx = response_text.rfind('}') + 1\n",
        "                json_str = response_text[start_idx:end_idx]\n",
        "                \n",
        "                result = json.loads(json_str)\n",
        "                if 'score' in result and 'reasoning' in result and 'category' in result:\n",
        "                    return result\n",
        "                else:\n",
        "                    raise ValueError(\"Invalid response structure\")\n",
        "                    \n",
        "            except Exception as parse_error:\n",
        "                print(f\"Parse error on attempt {attempt + 1}: {parse_error}\")\n",
        "                if attempt == max_retries - 1:\n",
        "                    return {\n",
        "                        \"score\": 0.5,\n",
        "                        \"reasoning\": \"Could not parse LLM response after multiple attempts\",\n",
        "                        \"category\": \"partial\"\n",
        "                    }\n",
        "                continue\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"API error on attempt {attempt + 1}: {e}\")\n",
        "            if \"insufficient_quota\" in str(e) or \"quota\" in str(e).lower():\n",
        "                print(\"⚠️  OpenAI API quota exceeded. Please check your billing.\")\n",
        "                return {\n",
        "                    \"score\": 0.0,\n",
        "                    \"reasoning\": \"API quota exceeded\",\n",
        "                    \"category\": \"error\"\n",
        "                }\n",
        "            elif attempt == max_retries - 1:\n",
        "                return {\n",
        "                    \"score\": 0.0,\n",
        "                    \"reasoning\": f\"API error after {max_retries} attempts: {str(e)}\",\n",
        "                    \"category\": \"error\"\n",
        "                }\n",
        "            continue\n",
        "\n",
        "    return {\n",
        "        \"score\": 0.0,\n",
        "        \"reasoning\": \"Unknown error occurred\",\n",
        "        \"category\": \"error\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Result 3.5: {'score': 0.0, 'reasoning': \"The candidate answer 'common fever' does not match any of the specific diagnoses mentioned in the ground truth (demam tifoid, demam berdarah, demam berdarah dengue).\", 'category': 'incorrect'}\n",
            "Test Result 4: {'score': 0.2, 'reasoning': \"The candidate answer 'common fever' is a very general term and does not specify the type of fever, while the ground truth answers are specific types of fevers (typhoid fever, dengue fever). Therefore, the candidate answer is partially correct but lacks specificity.\", 'category': 'partial'}\n"
          ]
        }
      ],
      "source": [
        "sample_question = \"Pasien mengalami demam pada waktu malam\"\n",
        "sample_candidate = \"Demam biasa\"\n",
        "sample_gt = \"Demam Tifoid 70%, Demam Berdarah Dengue 30%\"\n",
        "\n",
        "test_result = llm_judge_answer(sample_question, sample_candidate, sample_gt)\n",
        "print(f\"Test Result 3.5: {test_result}\")\n",
        "test_result = llm_judge_answer(sample_question, sample_candidate, sample_gt, model_name='gpt-4-0613')\n",
        "print(f\"Test Result 4: {test_result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_score_llm_judge(candidate_answers, question, gt_answers, model_name):\n",
        "    if not candidate_answers or not gt_answers:\n",
        "        return None, 0.0, {}\n",
        "    \n",
        "    best_score = 0.0\n",
        "    average_score = 0.0\n",
        "    \n",
        "    for candidate in tqdm(candidate_answers, desc=f'Processing cands {model_name}'):\n",
        "        judgment = llm_judge_answer(question, candidate, gt_answers, model_name)\n",
        "        score = judgment.get('score', 0.0)\n",
        "        average_score += score\n",
        "        \n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "    \n",
        "    cands = \",\".join(candidate_answers)\n",
        "    all_round_score = llm_judge_answer(question, cands, gt_answers, model_name).get('score', 0.0)\n",
        "    \n",
        "    return (average_score/len(candidate_answers)), best_score, all_round_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_row(row):\n",
        "    print(f\"Processing row {row.name}...\")\n",
        "    # truth_list = [item.strip() for item in row['Dr Answer'].split(',')]\n",
        "    model_cols = {\n",
        "        'Claude Answer': 'LLM_JUDGE_Claude',\n",
        "        'Qwen Answer': 'LLM_JUDGE_Qwen',\n",
        "        'GPT Answer': 'LLM_JUDGE_GPT',\n",
        "        'Deepseek RAG Answer': 'LLM_JUDGE_Deepseek_RAG',\n",
        "        'Deepseek non RAG Answer': 'LLM_JUDGE_Deepseek_nonRAG'\n",
        "    }\n",
        "    # gpt-3.5-turbo\n",
        "    # 'gpt-4-0613'\n",
        "    for col_name, result_col in tqdm(model_cols.items(), desc='Processing models'):\n",
        "        model_list = [item.strip() for item in row[col_name].split(',')]\n",
        "        row[f'{result_col}_avg_4'], row[f'{result_col}_best_4'], \\\n",
        "            row[f'{result_col}_all_4'] = find_score_llm_judge(model_list, row['Question'], row['Dr Answer'], model_name='gpt-4-0613')\n",
        "        row[f'{result_col}_avg_3.5'], row[f'{result_col}_best_3.5'], \\\n",
        "            row[f'{result_col}_all_3.5'] = find_score_llm_judge(model_list, row['Question'], row['Dr Answer'], model_name='gpt-3.5-turbo')\n",
        "    \n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 0...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.49s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.79s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.54s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.46s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 7/7 [00:24<00:00,  3.44s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 7/7 [00:07<00:00,  1.08s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:28<00:00, 29.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:20<00:00,  4.03s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.48s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.48s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.00s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.22s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:18<00:00,  3.07s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:06<00:00,  1.06s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:30<00:00, 30.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:13<00:00,  2.68s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.86s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:18<00:00,  3.00s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:05<00:00,  1.15it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:22<00:00,  3.81s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:18<00:00,  3.00s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:14<00:00, 26.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.77s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.64s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:07<00:00,  1.42s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.75s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.87s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.20s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:20<00:00,  4.14s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:31<00:00, 30.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.00it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:13<00:00,  2.70s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.29s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.82s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:18<00:00,  3.09s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:06<00:00,  1.07s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:11<00:00, 26.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.84s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.47s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.56s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.08it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:10<00:00, 26.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.32s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.20it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:13<00:00,  2.68s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.11s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.95s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
            "Processing models: 100%|██████████| 5/5 [01:59<00:00, 23.82s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.15s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.12it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.97s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.10it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.77s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.65s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:19<00:00,  3.19s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:20<00:00, 28.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.83s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.43s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.94s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.24s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:13<00:00, 26.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 9...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.95s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.09it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.60s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.14it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.41s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.38s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.94s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:10<00:00, 26.20s/it]\n"
          ]
        }
      ],
      "source": [
        "df2 = df.head(10)\n",
        "df2 = df2.apply(process_row, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 10...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.85s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.95s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.18s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.18s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.02s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:11<00:00, 26.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 11...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.63s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.48s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.80s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.75s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.00s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 3/3 [00:11<00:00,  3.81s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:18<00:00, 27.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 12...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.98s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.44s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:20<00:00,  4.20s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.63s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:22<00:00,  3.79s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:22<00:00, 28.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 13...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.54s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.69s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:20<00:00,  4.08s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.50s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 4/4 [00:16<00:00,  4.15s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:18<00:00, 27.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 14...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.68s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.33s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:08<00:00,  1.61s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.82s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.74s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 4/4 [00:13<00:00,  3.48s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:16<00:00, 27.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 15...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.36s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.47s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.44s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:24<00:00,  4.92s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:22<00:00, 28.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 16...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.98s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.95s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.09it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.41s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:13<00:00,  2.64s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.14s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:03<00:00, 24.79s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 17...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.08it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.11s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.28s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.46s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.84s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:11<00:00, 26.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 18...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.17s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.15it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.81s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.09it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:13<00:00,  2.73s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.90s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 4/4 [00:13<00:00,  3.37s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n",
            "Processing models: 100%|██████████| 5/5 [01:56<00:00, 23.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 19...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.97s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.35s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.24s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.47s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.10it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.94s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.13s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:04<00:00, 24.97s/it]\n"
          ]
        }
      ],
      "source": [
        "df3 = df.iloc[10:20]\n",
        "df3 = df3.apply(process_row, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 20...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:23<00:00,  4.65s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.28s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.81s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.27s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 9/9 [00:29<00:00,  3.29s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 9/9 [00:08<00:00,  1.01it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 2/2 [00:09<00:00,  4.68s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:39<00:00, 31.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 21...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:22<00:00,  4.42s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.12it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.75s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:22<00:00,  4.60s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.20it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.95s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.13it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 3/3 [00:11<00:00,  3.86s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:21<00:00, 28.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 22...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [10:18<00:00, 123.80s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.14it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.51s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:20<00:00,  4.06s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.08it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.93s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 4/4 [00:17<00:00,  4.42s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 4/4 [00:03<00:00,  1.05it/s]\n",
            "Processing models: 100%|██████████| 5/5 [12:24<00:00, 148.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 23...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 7/7 [00:28<00:00,  4.11s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 7/7 [00:06<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.83s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:22<00:00,  4.59s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.20s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.56s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:23<00:00,  3.91s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
            "Processing models: 100%|██████████| 5/5 [03:27<00:00, 41.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 24...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.59s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.21s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.96s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:42<00:00,  8.50s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.22s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 2/2 [00:11<00:00,  5.84s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:50<00:00, 34.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 25...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.44s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.48s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.75s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:13<00:00,  2.78s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 1/1 [00:03<00:00,  3.95s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
            "Processing models: 100%|██████████| 5/5 [01:58<00:00, 23.77s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 26...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 4/4 [00:08<00:00,  2.13s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 4/4 [00:04<00:00,  1.02s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.78s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.09it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.87s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.00s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 3/3 [00:11<00:00,  3.80s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:01<00:00, 24.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 27...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:22<00:00,  3.68s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.29s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.95s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:20<00:00,  4.15s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 4/4 [00:17<00:00,  4.43s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:38<00:00, 31.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 28...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:13<00:00,  2.73s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.21it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.50s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.88s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
            "Processing models: 100%|██████████| 5/5 [01:35<00:00, 19.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 29...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:10<00:00,  2.13s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:13<00:00,  2.66s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.97s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.96s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 4/4 [00:16<00:00,  4.01s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:07<00:00, 25.57s/it]\n"
          ]
        }
      ],
      "source": [
        "df4 = df.iloc[20:30]\n",
        "df4 = df4.apply(process_row, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 30...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:23<00:00,  4.71s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.28s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:20<00:00,  4.20s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:28<00:00,  5.76s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.66s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.13it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 7/7 [00:24<00:00,  3.47s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 7/7 [00:07<00:00,  1.05s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:51<00:00, 34.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 31...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.09s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:23<00:00,  4.61s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:26<00:00,  5.20s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.81s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 1/1 [00:04<00:00,  4.28s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:20<00:00, 28.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 32...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.77s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:20<00:00,  4.06s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.20s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.89s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.68s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 3/3 [00:12<00:00,  4.33s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 3/3 [00:03<00:00,  1.33s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:22<00:00, 28.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 33...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.31s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.00s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.26s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.32s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.86s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 3/3 [00:11<00:00,  3.78s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:14<00:00, 26.93s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 34...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:21<00:00,  3.58s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:23<00:00,  4.71s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.39s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:25<00:00,  5.13s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.93s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:55<00:00, 35.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 35...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.82s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.00s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.78s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.19s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.76s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.93s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:21<00:00, 28.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 36...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:22<00:00,  4.49s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.28s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:22<00:00,  4.46s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:08<00:00,  1.76s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.28s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 2/2 [00:10<00:00,  5.03s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:34<00:00, 30.87s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 37...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:22<00:00,  4.41s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.08it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:22<00:00,  4.54s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:23<00:00,  4.71s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.24s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:29<00:00,  4.95s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:52<00:00, 34.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 38...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.38s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.08it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.65s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.18s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.34s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.29s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 2/2 [00:06<00:00,  3.32s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:12<00:00, 26.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 39...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.59s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:23<00:00,  4.64s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.85s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.56s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 7/7 [00:38<00:00,  5.50s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 7/7 [00:07<00:00,  1.04s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:53<00:00, 34.71s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 40...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.57s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.86s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.23s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.18s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 3/3 [00:10<00:00,  3.60s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:18<00:00, 27.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 41...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.58s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.78s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.43s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:15<00:00,  3.16s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:17<00:00,  3.47s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:21<00:00, 28.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 42...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.64s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.00it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.67s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.10it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.92s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.76s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 7/7 [00:29<00:00,  4.23s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 7/7 [00:06<00:00,  1.04it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:33<00:00, 30.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 43...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 6/6 [00:22<00:00,  3.68s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 6/6 [00:05<00:00,  1.00it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:16<00:00,  3.38s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.37s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:07<00:00,  1.42s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:19<00:00,  3.83s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 3/3 [00:12<00:00,  4.12s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
            "Processing models: 100%|██████████| 5/5 [02:26<00:00, 29.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 44...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:14<00:00,  2.91s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:21<00:00,  4.37s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.16it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.63s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
            "Processing cands gpt-4-0613: 100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n",
            "Processing cands gpt-3.5-turbo: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "Processing models: 100%|██████████| 5/5 [02:02<00:00, 24.50s/it]\n"
          ]
        }
      ],
      "source": [
        "df5 = df.iloc[30:]\n",
        "df5 = df5.apply(process_row, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================= LLM-Based Judge Evaluation =================\n",
        "print(\"================ LLM-Based Judge Evaluation ================\")\n",
        "\n",
        "# LLMs to evaluate (excluding ground truth)\n",
        "llms_to_evaluate = [\n",
        "    \"Qwen 2.5 72B\",\n",
        "    \"GPT-4o mini\", \n",
        "    \"Deepseek-V3 (non RAG)\",\n",
        "    \"Deepseek-V3-RAG\"\n",
        "]\n",
        "\n",
        "# Store all results\n",
        "all_results_llm_judge = {}\n",
        "\n",
        "for llm_name in llms_to_evaluate:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Evaluating {llm_name} (LLM-based judge)\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    try:\n",
        "        llm_grouped = group_llm_answers(llm_name)\n",
        "        results = evaluate_llm_grouped_judge(llm_grouped, gt_grouped)\n",
        "        all_results_llm_judge[llm_name] = results\n",
        "        \n",
        "        # Calculate summary statistics\n",
        "        best_scores = [r['best_score'] for r in results]\n",
        "        matches = sum(r['match'] for r in results)\n",
        "        \n",
        "        print(f\"\\nSummary for {llm_name} (LLM-based judge):\")\n",
        "        print(f\"Matches: {matches} / {len(results)}\")\n",
        "        print(f\"Best Score - Mean: {np.mean(best_scores):.3f}, Std: {np.std(best_scores):.3f}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {llm_name}: {e}\")\n",
        "        all_results_llm_judge[llm_name] = []\n",
        "\n",
        "print(f\"\\nLLM-based judge evaluation completed for all LLMs!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create detailed results dataframe for LLM-based judge\n",
        "detailed_results_llm = []\n",
        "for llm_name, results in all_results_llm_judge.items():\n",
        "    if results:  # Only process if results exist\n",
        "        for result in results:\n",
        "            detailed_results_llm.append({\n",
        "                'LLM': llm_name,\n",
        "                'No': result['No'],\n",
        "                'Best_Score': result['best_score'],\n",
        "                'Match': result['match'],\n",
        "                'Category': result['judgment'].get('category', 'unknown'),\n",
        "                'Reasoning': result['judgment'].get('reasoning', 'No reasoning provided')\n",
        "            })\n",
        "\n",
        "if detailed_results_llm:\n",
        "    detailed_df_llm = pd.DataFrame(detailed_results_llm)\n",
        "    detailed_df_llm.to_csv('llm_diagnosis_evaluation_results_llm_judge.csv', index=False)\n",
        "    print(\"Detailed LLM-based judge results saved to 'llm_diagnosis_evaluation_results_llm_judge.csv'\")\n",
        "    \n",
        "    # Summary statistics for LLM-based judge\n",
        "    summary_data_llm = []\n",
        "    for llm_name, results in all_results_llm_judge.items():\n",
        "        if results:  # Only process if results exist\n",
        "            best_scores = [r['best_score'] for r in results]\n",
        "            matches = [r['match'] for r in results]\n",
        "            summary_data_llm.append({\n",
        "                'LLM': llm_name,\n",
        "                'Best_Score_Mean': np.mean(best_scores),\n",
        "                'Best_Score_Std': np.std(best_scores),\n",
        "                'Match_Rate': np.mean(matches),\n",
        "                'Best_Scores': best_scores,\n",
        "                'Matches': matches\n",
        "            })\n",
        "    \n",
        "    if summary_data_llm:\n",
        "        summary_df_llm = pd.DataFrame(summary_data_llm)\n",
        "        print(\"\\nSummary Statistics (LLM-based judge):\")\n",
        "        print(summary_df_llm[['LLM', 'Best_Score_Mean', 'Match_Rate']].round(3))\n",
        "        \n",
        "        # Display sample of detailed results\n",
        "        print(\"\\nSample of detailed results:\")\n",
        "        print(detailed_df_llm.head(10))\n",
        "    else:\n",
        "        print(\"No summary data to display - all evaluations may have failed\")\n",
        "else:\n",
        "    print(\"No detailed results to save - all evaluations may have failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize LLM-based judge results\n",
        "if 'summary_df_llm' in locals() and not summary_df_llm.empty:\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    \n",
        "    # 1. Bar plot of mean best scores\n",
        "    axes[0].bar(summary_df_llm['LLM'], summary_df_llm['Best_Score_Mean'], alpha=0.7, color='blue')\n",
        "    axes[0].set_title('Mean Best Score (LLM Judge)')\n",
        "    axes[0].set_ylabel('Score')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    axes[0].set_ylim(0, 1)\n",
        "    \n",
        "    # 2. Box plot of best scores\n",
        "    all_scores_llm = []\n",
        "    all_labels_llm = []\n",
        "    for _, row in summary_df_llm.iterrows():\n",
        "        all_scores_llm.extend(row['Best_Scores'])\n",
        "        all_labels_llm.extend([row['LLM']] * len(row['Best_Scores']))\n",
        "    \n",
        "    if all_scores_llm:\n",
        "        score_df_llm = pd.DataFrame({'LLM': all_labels_llm, 'Best_Score': all_scores_llm})\n",
        "        sns.boxplot(data=score_df_llm, x='LLM', y='Best_Score', ax=axes[1])\n",
        "        axes[1].set_title('Best Score Distribution by LLM (LLM Judge)')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "        axes[1].set_ylim(0, 1)\n",
        "    \n",
        "    # 3. Bar plot of match rate\n",
        "    axes[2].bar(summary_df_llm['LLM'], summary_df_llm['Match_Rate'], alpha=0.7, color='green')\n",
        "    axes[2].set_title('Match Rate by LLM (LLM Judge)')\n",
        "    axes[2].set_ylabel('Match Rate')\n",
        "    axes[2].set_ylim(0, 1)\n",
        "    axes[2].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Overall LLM Ranking (by mean best score)\n",
        "    print(\"\\nOverall LLM Ranking (by Mean Best Score):\")\n",
        "    ranking = summary_df_llm.sort_values('Best_Score_Mean', ascending=False)\n",
        "    for i, (_, row) in enumerate(ranking.iterrows()):\n",
        "        print(f\"{i+1}. {row['LLM']}: {row['Best_Score_Mean']:.3f}\")\n",
        "    \n",
        "    # Overall LLM Ranking (by Match Rate)\n",
        "    print(\"\\nOverall LLM Ranking (by Match Rate):\")\n",
        "    ranking_match = summary_df_llm.sort_values('Match_Rate', ascending=False)\n",
        "    for i, (_, row) in enumerate(ranking_match.iterrows()):\n",
        "        print(f\"{i+1}. {row['LLM']}: {row['Match_Rate']:.3f}\")\n",
        "        \n",
        "else:\n",
        "    print(\"No visualization data available - evaluations may have failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance Analysis by Question (LLM Judge)\n",
        "if 'detailed_df_llm' in locals() and not detailed_df_llm.empty:\n",
        "    print(\"Performance Analysis by Question (LLM Judge):\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Group by question number to see which questions are harder\n",
        "    question_performance = detailed_df_llm.groupby('No').agg({\n",
        "        'Best_Score': ['mean', 'std'],\n",
        "        'Match': ['mean']\n",
        "    }).round(3)\n",
        "    \n",
        "    question_performance.columns = ['Best_Score_Mean', 'Best_Score_Std', 'Match_Rate']\n",
        "    question_performance = question_performance.reset_index()\n",
        "    \n",
        "    print(\"Questions with lowest average scores:\")\n",
        "    worst_questions = question_performance.nsmallest(5, 'Best_Score_Mean')\n",
        "    print(worst_questions)\n",
        "    \n",
        "    print(\"\\nQuestions with highest average scores:\")\n",
        "    best_questions = question_performance.nlargest(5, 'Best_Score_Mean')\n",
        "    print(best_questions)\n",
        "    \n",
        "    # Category analysis\n",
        "    print(\"\\nCategory Distribution:\")\n",
        "    category_counts = detailed_df_llm['Category'].value_counts()\n",
        "    print(category_counts)\n",
        "    \n",
        "else:\n",
        "    print(\"No performance data available for analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EVALUATION SUMMARY (LLM Judge)\n",
        "print(\"LLM-BASED JUDGE EVALUATION SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'summary_df_llm' in locals() and not summary_df_llm.empty:\n",
        "    # Best performing LLMs\n",
        "    best_score_idx = summary_df_llm['Best_Score_Mean'].idxmax()\n",
        "    best_match_idx = summary_df_llm['Match_Rate'].idxmax()\n",
        "    \n",
        "    best_semantic = summary_df_llm.loc[best_score_idx]\n",
        "    best_match = summary_df_llm.loc[best_match_idx]\n",
        "    \n",
        "    print(f\"Best LLM by Score: {best_semantic['LLM']} (Score: {best_semantic['Best_Score_Mean']:.3f})\")\n",
        "    print(f\"Best LLM by Match Rate: {best_match['LLM']} (Rate: {best_match['Match_Rate']:.3f})\")\n",
        "    \n",
        "    # Overall statistics\n",
        "    print(f\"\\nOverall Statistics:\")\n",
        "    print(f\"Total Questions Evaluated: {len(gt_grouped)}\")\n",
        "    print(f\"Total LLMs Evaluated: {len(summary_df_llm)}\")\n",
        "    print(f\"Average Score Across All LLMs: {summary_df_llm['Best_Score_Mean'].mean():.3f}\")\n",
        "    print(f\"Average Match Rate Across All LLMs: {summary_df_llm['Match_Rate'].mean():.3f}\")\n",
        "    \n",
        "    # Recommendations\n",
        "    print(\"\\nRECOMMENDATIONS:\")\n",
        "    print(\"1. Use LLM-based judge scores for nuanced medical diagnosis evaluation.\")\n",
        "    print(\"2. Consider both mean score and match rate for comprehensive assessment.\")\n",
        "    print(\"3. Review low-scoring questions for common diagnostic challenges.\")\n",
        "    print(\"4. Use category analysis to understand error types and patterns.\")\n",
        "    \n",
        "    print(\"\\nEvaluation completed successfully!\")\n",
        "    print(\"Check 'llm_diagnosis_evaluation_results_llm_judge.csv' for detailed results.\")\n",
        "    \n",
        "else:\n",
        "    print(\"Evaluation failed or no results available.\")\n",
        "    print(\"Please check your OpenAI API key and internet connection.\")\n",
        "    print(\"You may need to run the evaluation cells again.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
